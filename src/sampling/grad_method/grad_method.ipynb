{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean energy: -632.1508865356445\n",
      "Best mean energy -772.1880859375\n"
     ]
    }
   ],
   "source": [
    "# increase alpha depend on differential value\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import output\n",
    "import importlib\n",
    "importlib.reload(output)\n",
    "\n",
    "# mの正負に応じてイジングモデルのエネルギーを計算\n",
    "# Not devided by N-1\n",
    "def energy(m, h, J):\n",
    "    m = 2 * (m > 0.0) - 1\n",
    "    return -torch.sum(h * m) - (torch.sum(J * torch.outer(m, m)) - torch.sum(torch.diagonal(J * torch.outer(m, m))))\n",
    "\n",
    "# エネルギー計算関数 (ベクトル化)\n",
    "# Not devided by N-1\n",
    "def f(m, h, J, tau, alpha):\n",
    "    AS = -(1 - alpha) * torch.sum(torch.log(1 - m**2))\n",
    "    interaction = (torch.sum(J * torch.outer(m, m)) - torch.sum(torch.diagonal(J * torch.outer(m, m)))) \n",
    "    ising = -alpha * (torch.sum(h * m) + interaction)\n",
    "    return AS + ising\n",
    "\n",
    "# 勾配計算関数 (ベクトル化)\n",
    "# Not devided by N-1\n",
    "def update(m, h, J, tau, alpha):\n",
    "    interaction_grad = -alpha * (torch.sum(J * m, dim=1) - torch.diagonal(J) * m) \n",
    "    dif = interaction_grad + (1 - alpha) * m / (1 - m**2) - alpha * h\n",
    "    return dif\n",
    "\n",
    "# 勾配降下法 (改良版)\n",
    "def gradient_descent(m, h, J, tau, alpha, alpha_inc, max_iter, lr, tol):\n",
    "    best_energy = 0\n",
    "    alpha_cnt = 0\n",
    "    for iteration in range(max_iter):\n",
    "        grad = update(m, h, J, tau, alpha)\n",
    "        m = m - lr * grad  # 勾配降下ステップ\n",
    "        if best_energy > energy(m, h, J):\n",
    "            best_energy = energy(m, h, J)\n",
    "\n",
    "        # 停滞のチェック（勾配が小さくなる場合）\n",
    "        if torch.max(abs(grad)) < tol:\n",
    "            alpha = min(alpha + alpha_inc, 0.9999)  # alpha を増加\n",
    "            alpha_cnt += 1\n",
    "\n",
    "        ## alpha が 0.99 に達した場合、終了\n",
    "        #if alpha >= 0.999:\n",
    "        #    break\n",
    "    return energy(m, h, J), best_energy, alpha_cnt\n",
    "\n",
    "# シード値の設定\n",
    "def initialize_random_parameters(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    J = torch.normal(mean=0.0, std=1.0, size=(n, n))\n",
    "    return J\n",
    "\n",
    "# 初期条件\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42\n",
    "n = 100\n",
    "h = 0.0001\n",
    "alpha_inc = 0.01\n",
    "tau = torch.tensor(1000, device=device)\n",
    "max_iter = 1000000\n",
    "lr = 0.01\n",
    "tol = 1e-5\n",
    "final_list = []\n",
    "best_list = []\n",
    "alpha_cnt_list = []\n",
    "\n",
    "for i in range(20):\n",
    "    m = torch.zeros(n, device=device)\n",
    "    J = initialize_random_parameters(n, seed).to(device)\n",
    "    alpha = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 勾配降下法を実行\n",
    "    final_energy, best_energy, alpha_cnt = gradient_descent(m, h, J, tau, alpha, alpha_inc, max_iter, lr, tol)\n",
    "\n",
    "    # リストに追加\n",
    "    final_list.append(final_energy.cpu().item())\n",
    "    best_list.append(best_energy.cpu().item())\n",
    "    alpha_cnt_list.append(alpha_cnt)\n",
    "\n",
    "    # modify seed value\n",
    "    seed += 1\n",
    "\n",
    "matrix = [[f, b, a] for f, b, a in zip(final_list, best_list, alpha_cnt_list)]\n",
    "matrix.insert(0, ['final', 'best', 'alpha'])\n",
    "result = output.matrix_to_csv(f'alpha{alpha_inc}_lr{lr}_tol{tol}', matrix)\n",
    "\n",
    "# 最終結果を出力\n",
    "print(\"Final mean energy:\", np.mean(final_list))\n",
    "print(\"Best mean energy\", np.mean(best_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, -2])\n",
    "print((torch.min(abs(a)).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999\n",
      "Final mean energy: -65.22675323486328\n"
     ]
    }
   ],
   "source": [
    "# increase alpha depend on the schedule\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# mの正負に応じてイジングモデルのエネルギーを計算\n",
    "# Not devided by N-1\n",
    "def energy(m, h, J):\n",
    "    m = 2 * (m > 0.0) - 1\n",
    "    return -torch.sum(h * m) - (torch.sum(J * torch.outer(m, m)) - torch.sum(torch.diagonal(J * torch.outer(m, m))))\n",
    "\n",
    "# エネルギー計算関数 (ベクトル化)\n",
    "# Not devided by N-1\n",
    "def f(m, h, J, tau, alpha):\n",
    "    AS = -(1 - alpha) * torch.sum(torch.log(1 - m**2))\n",
    "    interaction = (torch.sum(J * torch.outer(m, m)) - torch.sum(torch.diagonal(J * torch.outer(m, m))))\n",
    "    ising = -alpha * (torch.sum(h * m) + interaction)\n",
    "    return AS + ising\n",
    "\n",
    "# 勾配計算関数 (ベクトル化)\n",
    "# Not devided by N-1\n",
    "def update(m, h, J, tau, alpha):\n",
    "    interaction_grad = -alpha * (torch.sum(J * m, dim=1) - torch.diagonal(J) * m)\n",
    "    dif = interaction_grad + (1 - alpha) * m / (1 - m**2) - alpha * h\n",
    "    return dif\n",
    "\n",
    "# 勾配降下法 (改良版)\n",
    "def gradient_descent(m, h, J, tau, alpha, max_iter, tol=1e-6):\n",
    "    learning_rate = 0.01\n",
    "    for iteration in range(max_iter):\n",
    "        grad = update(m, h, J, tau, alpha)\n",
    "        m = m - learning_rate * grad  # 勾配降下ステップ\n",
    "\n",
    "        alpha = min(alpha + (1 / max_iter), 0.999999)\n",
    "\n",
    "    print(alpha)\n",
    "    return energy(m, h, J)\n",
    "\n",
    "# シード値の設定\n",
    "def initialize_random_parameters(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    J = torch.normal(mean=0.0, std=1.0, size=(n, n))\n",
    "    return J\n",
    "\n",
    "# 初期条件\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42\n",
    "n = 100\n",
    "h = 0.0001\n",
    "tau = torch.tensor(1000, device=device)\n",
    "max_iter = 1000000\n",
    "final_list = []\n",
    "\n",
    "for i in range(1):\n",
    "    m = torch.zeros(n, device=device)\n",
    "    J = initialize_random_parameters(n, seed).to(device)\n",
    "    alpha = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 勾配降下法を実行\n",
    "    final_energy = gradient_descent(m, h, J, tau, alpha, max_iter).cpu().item()\n",
    "\n",
    "    # リストに追加\n",
    "    final_list.append(final_energy)\n",
    "\n",
    "    # modify seed value\n",
    "    seed += 1\n",
    "\n",
    "# 最終結果を出力\n",
    "print(\"Final mean energy:\", np.mean(final_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
