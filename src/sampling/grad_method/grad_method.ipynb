{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase alpha depend on differential value\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import output\n",
    "import importlib\n",
    "import grad_aco\n",
    "importlib.reload(output)\n",
    "\n",
    "# 初期条件\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n = 100\n",
    "h = 0.0001\n",
    "alpha = 0.0\n",
    "alpha_inc = [0.01, 0.005, 0.001]\n",
    "tau = torch.tensor(1000, device=device)\n",
    "max_iter = 1000000\n",
    "lr = [0.001, 0.01, 0.1]\n",
    "tol = [1e-4, 1e-5, 1e-6]\n",
    "seed = 42\n",
    "\n",
    "\n",
    "for a_inc in alpha_inc:\n",
    "    for lerning_rate in lr:\n",
    "        for tolerance in tol:\n",
    "            final_list = []\n",
    "            best_list = []\n",
    "            alpha_cnt_list = []\n",
    "            for i in range(5):\n",
    "                m = torch.zeros(n, device=device)\n",
    "                J = grad_aco.initialize_random_parameters(n, seed).to(device)\n",
    "                alpha = torch.tensor(0.0, device=device)\n",
    "\n",
    "                # 勾配降下法を実行\n",
    "                final_energy, best_energy, alpha_cnt = grad_aco.gradient_descent(m, h, J, tau, alpha, a_inc, max_iter, lerning_rate, tolerance)\n",
    "\n",
    "                # リストに追加\n",
    "                final_list.append(final_energy.cpu().item())\n",
    "                best_list.append(best_energy.cpu().item())\n",
    "                alpha_cnt_list.append(alpha_cnt)\n",
    "\n",
    "                # modify seed\n",
    "                seed += 1\n",
    "            \n",
    "            # fix seed\n",
    "            seed = 42\n",
    "\n",
    "            #save to csv file\n",
    "            matrix = [[f, b, a] for f, b, a in zip(final_list, best_list, alpha_cnt_list)]\n",
    "            matrix.insert(0, ['final', 'best', 'alpha'])\n",
    "            result = output.matrix_to_csv(f'alpha{a_inc}_lr{lerning_rate}_tol{tolerance}_seed{seed}', matrix)\n",
    "\n",
    "#matrix = [[f, b, a] for f, b, a in zip(final_list, best_list, alpha_cnt_list)]\n",
    "#matrix.insert(0, ['final', 'best', 'alpha'])\n",
    "#result = output.matrix_to_csv(f'alpha{a_inc}_lr{lerning_rate}_tol{tolerance}_seed{seed}', matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999\n",
      "Final mean energy: -65.22675323486328\n"
     ]
    }
   ],
   "source": [
    "# increase alpha depend on the schedule\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# mの正負に応じてイジングモデルのエネルギーを計算\n",
    "# Not devided by N-1\n",
    "def energy(m, h, J):\n",
    "    m = 2 * (m > 0.0) - 1\n",
    "    return -torch.sum(h * m) - (torch.sum(J * torch.outer(m, m)) - torch.sum(torch.diagonal(J * torch.outer(m, m))))\n",
    "\n",
    "# エネルギー計算関数 (ベクトル化)\n",
    "# Not devided by N-1\n",
    "def f(m, h, J, tau, alpha):\n",
    "    AS = -(1 - alpha) * torch.sum(torch.log(1 - m**2))\n",
    "    interaction = (torch.sum(J * torch.outer(m, m)) - torch.sum(torch.diagonal(J * torch.outer(m, m))))\n",
    "    ising = -alpha * (torch.sum(h * m) + interaction)\n",
    "    return AS + ising\n",
    "\n",
    "# 勾配計算関数 (ベクトル化)\n",
    "# Not devided by N-1\n",
    "def update(m, h, J, tau, alpha):\n",
    "    interaction_grad = -alpha * (torch.sum(J * m, dim=1) - torch.diagonal(J) * m)\n",
    "    dif = interaction_grad + (1 - alpha) * m / (1 - m**2) - alpha * h\n",
    "    return dif\n",
    "\n",
    "# 勾配降下法 (改良版)\n",
    "def gradient_descent(m, h, J, tau, alpha, max_iter, tol=1e-6):\n",
    "    learning_rate = 0.01\n",
    "    for iteration in range(max_iter):\n",
    "        grad = update(m, h, J, tau, alpha)\n",
    "        m = m - learning_rate * grad  # 勾配降下ステップ\n",
    "\n",
    "        alpha = min(alpha + (1 / max_iter), 0.999999)\n",
    "\n",
    "    print(alpha)\n",
    "    return energy(m, h, J)\n",
    "\n",
    "# シード値の設定\n",
    "def initialize_random_parameters(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    J = torch.normal(mean=0.0, std=1.0, size=(n, n))\n",
    "    return J\n",
    "\n",
    "# 初期条件\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42\n",
    "n = 100\n",
    "h = 0.0001\n",
    "tau = torch.tensor(1000, device=device)\n",
    "max_iter = 1000000\n",
    "final_list = []\n",
    "\n",
    "for i in range(1):\n",
    "    m = torch.zeros(n, device=device)\n",
    "    J = initialize_random_parameters(n, seed).to(device)\n",
    "    alpha = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 勾配降下法を実行\n",
    "    final_energy = gradient_descent(m, h, J, tau, alpha, max_iter).cpu().item()\n",
    "\n",
    "    # リストに追加\n",
    "    final_list.append(final_energy)\n",
    "\n",
    "    # modify seed value\n",
    "    seed += 1\n",
    "\n",
    "# 最終結果を出力\n",
    "print(\"Final mean energy:\", np.mean(final_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
